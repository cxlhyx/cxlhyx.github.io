{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  # request库爬取源码\n",
    "from bs4 import BeautifulSoup  # 解析源码\n",
    "from fake_useragent import UserAgent  # 随机获取请求头\n",
    "from tqdm import trange\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: 访问网页并获取响应内容\n",
    "def get_html_content(url):\n",
    "    headers = {\n",
    "        'User-Agent': UserAgent().random\n",
    "    }  # 请求头，爬虫程序通过加上请求头伪装成浏览器\n",
    "    data = {'name': 'huoyouxing'}\n",
    "    try:\n",
    "        response = requests.get(url, data=data, headers=headers)\n",
    "        response.raise_for_status()  # 判断返回的Response类型状态是不是200\n",
    "        response.encoding = response.apparent_encoding  # 从内容中分析出的响应内容编码\n",
    "        html_content = response.text  # 网页内容\n",
    "        return html_content  # 返回网页内容\n",
    "    except Exception as e:\n",
    "        print(f\"网页请求异常：{e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: 解析网页并提取目标数据\n",
    "def parse_html(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')  # 解析 html 数据\n",
    "    # TODO：根据需求编写解析代码，并将结果保存到合适的数据结构中\n",
    "    data_list = []\n",
    "    data_list.append([[j.text.replace(\"\\xa0/\\xa0\", \"\") for j in i.find_all('span', ['title', 'other'])]\n",
    "                        for i in soup.find_all('div', 'hd')])  # 电影名\n",
    "    wwww = []\n",
    "    for i in soup.find_all('div', 'bd'):\n",
    "        tmp = []\n",
    "        for j in i.find('p', _class=''):\n",
    "            text = j.text.replace(\"\\xa0\\xa0\\xa0\", '\\\\')\n",
    "            text = text.replace(\"\\xa0\", \"\")\n",
    "            text = text.replace(\"\\n\", \"\")\n",
    "            text = text.replace(\" \", \"\")\n",
    "            if text != \"\" and text != '豆瓣':\n",
    "                tmp.append(text)\n",
    "        if len(tmp) != 0:\n",
    "            wwww.append(tmp)\n",
    "    data_list.append(wwww)  # who when where what\n",
    "    data_list.append([i.text for i in soup.find_all('span', {'class': \"rating_num\", 'property': \"v:average\"})])  # 评分\n",
    "    About = []\n",
    "    for i in soup.find_all('div', 'info'):\n",
    "        if i.find('span', 'inq'):\n",
    "            About.append(i.find('span', 'inq').text)\n",
    "        else:\n",
    "            About.append(\" \")\n",
    "    data_list.append(About)  # 简介\n",
    "    return data_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: 存储数据到本地或其他持久化存储服务器中\n",
    "def store_data(result_list):\n",
    "    # TODO：编写存储代码，将数据结果保存到本地或其他服务器中\n",
    "    \"\"\"with open(\"豆瓣电影Top25011.txt\", 'a', encoding='utf-8') as file:\n",
    "        for i in range(25):\n",
    "            if len(result_list[0][i]) == 2:\n",
    "                file.write(\"Chinese name: \" + result_list[0][i][0] + '\\n')\n",
    "                file.write(\"Other name: \" + result_list[0][i][1] + '\\n')\n",
    "            elif len(result_list[0][i]) == 3:\n",
    "                file.write(\"Chinese name: \" + result_list[0][i][0] + '\\n')\n",
    "                file.write(\"Foreign name: \" + result_list[0][i][1] + '\\n')\n",
    "                file.write(\"Other name: \" + result_list[0][i][2] + '\\n')\n",
    "            file.write(\"Who: \" + result_list[1][i][0] + '\\n')\n",
    "            file.write(\"When/Where/What: \" + result_list[1][i][1] + '\\n')\n",
    "            file.write(\"Score: \" + result_list[2][i] + '\\n')\n",
    "            file.write(\"About: \" + result_list[3][i] + '\\n')\n",
    "            file.write('=' * 50 + '\\n')\"\"\"\n",
    "    global total\n",
    "    for i in range(25):\n",
    "        each=[]\n",
    "        if len(result_list[0][i]) == 2:\n",
    "            each.append(result_list[0][i][0])  # Chinese name\n",
    "            each.append(\" \")  # Foreign name为空\n",
    "            each.append(result_list[0][i][1])  # Other name\n",
    "        elif len(result_list[0][i]) == 3:\n",
    "            each.append(result_list[0][i][0])  # Chinese name\n",
    "            each.append(result_list[0][i][1])  # Foreign name\n",
    "            each.append(result_list[0][i][2])  # Other name\n",
    "        each.append(result_list[1][i][0])  # who\n",
    "        each.append(result_list[1][i][1])  # When/Where/What\n",
    "        each.append(result_list[2][i])  # Score\n",
    "        each.append(result_list[3][i])  # About\n",
    "        total.append(each)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 4: 控制流程，调用上述函数完成数据抓取任务\n",
    "global total\n",
    "total=[]\n",
    "url = \"https://movie.douban.com/top250?start=\"\n",
    "for page in trange(0, 250, 25):\n",
    "    target_url = url + str(page)\n",
    "    html_content = get_html_content(target_url)\n",
    "    if html_content:\n",
    "        result_list = parse_html(html_content)\n",
    "        store_data(result_list)\n",
    "    else:\n",
    "        print(\"网页访问失败\")\n",
    "total_df=pd.DataFrame(total)\n",
    "total_df.columns=['Chinese name','Foreign name','Other name','who','When/Where/What','Score','About']\n",
    "# total_df.to_csv('豆瓣电影Top250.csv')\n",
    "total_df.to_excel('豆瓣电影Top250.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
